{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "debug_flag = True # use this while tuning the KEY PARAMETERS\n",
    "\n",
    "filename = \"SM2p2_comp\" # filename of video to be processed\n",
    "vid_ext = \".mp4\" # extension of video to be processed\n",
    "# choose from SM3, SM2, SM1.1, SM1.2-4, RR2_low, RR2_mid, RR1 for correct settings\n",
    "id_str = \"SM2\"\n",
    "\n",
    "IMG_SIZE = 64 # needs to be the same as the tf model trained\n",
    "frame_start = 0 # normally should be 0\n",
    "# how many frames from frame start will it last for, a really large number just means let the video run until its finished.\n",
    "frame_end = 1000000000\n",
    "\n",
    "# for smoothing the tracks before rectification\n",
    "smoothing_val_small = 2 # this is for horizontal smoothing\n",
    "smoothing_val = 4 # this is for vertical smoothing\n",
    "min_ride_duration = 2 # seconds\n",
    "min_ride_length = 4 # metres\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%% KEY PARAMETERS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "\n",
    "########### Background Subtraction Variables #######################\n",
    "processing_area_bottom = 0.55 # only process breaking waves above this region\n",
    "processing_area_top = 0.15 # only process breaking waves below this region\n",
    "processing_area_left = 0.1 # only process breaking waves to the right of this region\n",
    "processing_area_right = 0.8 # only process breaking waves to the left of this region\n",
    "# this value was found to be useful to allow more or less motion to be detected for blob detection.\n",
    "# The value ranges from 0 to 255 and must be an int. The range of 1-50 works best. 0,1 or 2 often \n",
    "# does not work due to pixelated nature of videos the higher the motion sensitivity value the better \n",
    "# in terms of algorithm speed\n",
    "motion_sensitivity = 15 \n",
    "# use (10,10) normally, reduces the sensitivity of motion detection by bluring high movement noisy areas \n",
    "# like the foam in the water. \n",
    "blur_pixels = (20,20)\n",
    "\n",
    "# determines the minimum size of the movement seen, this parameter will have some relation to the swell size\n",
    "blob_area_min = 1 \n",
    "# determines how many frames back the algorithm looks to compare the current frame with for motion detection\n",
    "frame_comparison_range = 2 \n",
    "\n",
    "########### Classification Variables #######################\n",
    "# determines how confident the algorithm has to be of an object being a breaking wave\n",
    "classification_threshold = 0.95\n",
    "# this value determines the size of the snapshots of the detected areas of motion.\n",
    "# The size of the bounding box will be 'bbox_size'*3 x 'bbox_size'*2 (width x height)\n",
    "# These snapshots will be sent through a classifier to determine whether they contain a breaking wave or not\n",
    "# the greater the size of the bouding box the more computations it will take to perform classification, however the\n",
    "# bounding box needs to be large enough to fit the largest breaking wave inside. Ideally a dynamic bounding box sizer would be ideal\n",
    "bbox_size = 50\n",
    "\n",
    "########### Tracking Variables #######################\n",
    "# need to have tracked an object for at least this many frames for it to be given an ID. \n",
    "# Mostly for user visualization purposes. all data is still stored\n",
    "trackable_threshold = 5 \n",
    "# 0.5 means height and width are equally weighted for euclidean distance calc (which dist_coef is concerned with).\n",
    "# 0.9 for example allows more vertical variation but restricts horizontal variation. vice versa for 0.1\n",
    "LW_ratio = 0.25 \n",
    "# a larger number makes the algorithm less effective at tracking fast objects, but more reliable in terms of not \n",
    "# ID swapping with a neaby object\n",
    "dist_coef = 70 \n",
    "\n",
    "expiry_countdown = 3*10 # determines how many frames an object is remembered for while occlusion is occuring\n",
    "cost_threshold = 1.0 # how lenient is the program in associating a tracked object with an object in the image\n",
    "time_coef = 1.0 # larger number allows less re-detections, lower number allows more re-detections after a FN or occlusion\n",
    "\n",
    "# overlap_coef not used, diff_coef not used\n",
    "# this value is large such that if there is any overlap between an object and the next position of the object, \n",
    "# the algorithm considers it the same object\n",
    "overlap_coef = 1000 \n",
    "# larger number allows less shape changing of object, lower number allows the shape of the object to \n",
    "# change more and still be tracked\n",
    "diff_coef = 0.6 \n",
    "\n",
    "cap = cv2.VideoCapture(filename + vid_ext) # put the movie type extension here\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS) #fps\n",
    "\n",
    "# create a new folder to store all the results in\n",
    "current_path = os.getcwd()\n",
    "results_dir = filename + \"_results\"\n",
    "results_dir_path = os.path.join(current_path, results_dir)\n",
    "if os.path.exists(results_dir_path):\n",
    "    shutil.rmtree(results_dir_path)\n",
    "    print(\"old results directory removed\")\n",
    "os.mkdir(results_dir_path)\n",
    "print(\"new results directory created called \" + results_dir)\n",
    "\n",
    "cap.set(1, frame_start)\n",
    "\n",
    "# view the image\n",
    "ret, frame_rec = cap.read()\n",
    "\n",
    "frame_skip = 0 # allows for same frame rate for 50fps SM videos\n",
    "if id_str == \"SM3\":\n",
    "    frame_skip = 2\n",
    "    model_scale_factor_dist = 32\n",
    "    model_name = 'wave_tracking_tf_lab_sm_v35.model'\n",
    "    \n",
    "    #              W1_9, W1_8, W1_7, W2_5, W2_4, W2_0,  C_0, E2_0, E2_2, E2_4, E1_5, E1_7, E1_9,  C_9,  C_8,  C_7,  C_3,  C_4 \n",
    "    x_vals_pre =  [1653, 1553, 1482, 1832, 1766, 1522,  961,  350,  227,   59,  452,  339,  126,  913,  930,  944,  959,  954] \n",
    "    y_vals_pre =  [ 573,  502,  441,  359,  335,  240,  242,  243,  283,  338,  367,  442,  568,  571,  501,  445,  307,  334]\n",
    "    x_vals_post = [ 187,  215,  246,  301,  329,  478,  478,  478,  402,  330,  302,  246,  187,  187,  215,  245,  365,  330] \n",
    "    y_vals_post = [ 234,  234,  234,  164,  164,  164,  303,  454,  455,  455,  380,  379,  379,  303,  303,  303,  304,  304]\n",
    "    y_vals_post = (606 - np.array(y_vals_post)).tolist()\n",
    "    easting_scale = 0.040746497\n",
    "    northing_scale = 0.024422442\n",
    "    post_rect_name = \"IMG_TSBMound3ContourPlot_V000_20220505.png\"\n",
    "    \n",
    "    if filename[-1] == \"5\" or filename[-1] == \"4\":\n",
    "        test_duration = 320 # seconds\n",
    "    else:\n",
    "        test_duration = 55 # seconds\n",
    "        \n",
    "elif id_str == \"SM2\":\n",
    "    frame_skip = 2\n",
    "    model_scale_factor_dist = 32\n",
    "    model_name = 'wave_tracking_tf_lab_sm_v35.model'\n",
    "    \n",
    "    # SM2          W1_9, W2_7, W2_4, W3_2, W1_2,  C_2, E1_2, E3_2, E2_4, E2_7, E1_8, E1_9,  C_8, CR_3, CR_2, CR_1\n",
    "    x_vals_pre =  [1480, 1653, 1424, 1570, 1078,  850,  599,   82,  252,   76,  481,  441,  959,  578,  903, 1102] \n",
    "    y_vals_pre =  [ 437,  344,  275,  238,  237,  235,  234,  232,  270,  348,  391,  442,  388,  341,  303,  279]\n",
    "    x_vals_post = [ 188,  248,  331,  404,  404,  404,  405,  405,  333,  248,  216,  189,  216,  251,  290,  322]\n",
    "    y_vals_post = [ 243,  171,  171,   82,  244,  316,  395,  550,  474,  474,  395,  395,  316,  383,  315,  260]\n",
    "    y_vals_post = (631 - np.array(y_vals_post)).tolist()\n",
    "    easting_scale = 0.040465823\n",
    "    northing_scale = 0.023454834\n",
    "    post_rect_name = \"IMG_TSBMound2ContourPlot_V000_20220505.png\"\n",
    "    \n",
    "    if filename[-1] == \"5\" or filename[-1] == \"4\":\n",
    "        test_duration = 320 # seconds\n",
    "    else:\n",
    "        test_duration = 55 # seconds\n",
    "    \n",
    "elif id_str == \"SM1.1\":\n",
    "    frame_skip = 2\n",
    "    model_scale_factor_dist = 32\n",
    "    model_name = 'wave_tracking_tf_lab_sm_v35.model'\n",
    "    \n",
    "    # SM1.1            1    2    3    4     5     6     7     8    9\n",
    "    x_vals_pre =  [  197, 171, 318, 760, 1226, 1680, 1744, 1647, 866] \n",
    "    y_vals_pre =  [  403, 317, 253, 240,  229,  230,  310,  447, 466]\n",
    "    x_vals_post = [  131, 169, 217, 228,  240,  235,  173,  119, 114]\n",
    "    y_vals_post = [  389, 418, 423, 341,  246,  153,  184,  230, 311]\n",
    "    y_vals_post = (613 - np.array(y_vals_post)).tolist()\n",
    "    easting_scale = 0.04167927\n",
    "    northing_scale = 0.024143556\n",
    "    post_rect_name = \"IMG_TSBMound1ContourPlot_V000_20220505.png\"\n",
    "    \n",
    "    test_duration = 55 # seconds\n",
    "    \n",
    "elif id_str == \"SM1.2-4\":\n",
    "    frame_skip = 2\n",
    "    model_scale_factor_dist = 32\n",
    "    model_name = 'wave_tracking_tf_lab_sm_v35.model'\n",
    "    \n",
    "    # SM1.2-4         10,  11,   12,   13,   14\n",
    "    x_vals_pre =  [  167, 512,  934, 1457, 1542] \n",
    "    y_vals_pre =  [  320, 134,  125,  136,  369]\n",
    "    x_vals_post = [  169, 437,  476,  422,  144]\n",
    "    y_vals_post = [  420, 474,  313,  119,  229]\n",
    "    y_vals_post = (613 - np.array(y_vals_post)).tolist()\n",
    "    easting_scale = 0.04167927\n",
    "    northing_scale = 0.024143556\n",
    "    post_rect_name = \"IMG_TSBMound1ContourPlot_V000_20220505.png\"\n",
    "    \n",
    "    if filename[-1] == \"4\" or filename[-1] == \"3\":\n",
    "        test_duration = 320 # seconds\n",
    "    else:\n",
    "        test_duration = 55 # seconds\n",
    "    \n",
    "elif id_str == \"RR2_low\":\n",
    "    model_scale_factor_dist = 29.5\n",
    "    model_name = 'wave_tracking_tf_lab_sm_v28.model'\n",
    "    \n",
    "    #             # G19   G24   G38  G39   G31 G40E  G26  G11\n",
    "    x_vals_pre =  [ 133, 1209, 1046, 716, 1112, 358, 242, 776] \n",
    "    y_vals_pre =  [ 457,  319,  205, 213,  254, 223, 346, 633]\n",
    "    y_vals_post = [ 392,  237,  235, 311,  236, 394, 393, 316]\n",
    "    x_vals_post = [ 545,  457,  281, 280,  369, 280, 457, 633]\n",
    "    x_vals_post = (764 - np.array(x_vals_post)).tolist()\n",
    "    y_vals_post = (615 - np.array(y_vals_post)).tolist()\n",
    "    easting_scale = 0.02617801 # design I\n",
    "    northing_scale = 0.022764228\n",
    "    post_rect_name = \"IMG_DesignIContourPlot_V000_20220505.png\"\n",
    "    \n",
    "    if filename[-2] == \"3\":\n",
    "        test_duration = 329 # seconds\n",
    "    else:\n",
    "        test_duration = 50 # seconds\n",
    "    \n",
    "elif id_str == \"RR2_mid\":\n",
    "    model_scale_factor_dist = 29.5\n",
    "    model_name = 'wave_tracking_tf_lab_sm_v28.model'\n",
    "    \n",
    "    #             # G19   G24   G38  G39   G31 G40E  G26  G11\n",
    "    x_vals_pre =  [  75, 1225, 1055, 701, 1126, 319, 193, 763] \n",
    "    y_vals_pre =  [ 462,  320,  197, 206,  248, 216, 344, 653]\n",
    "    y_vals_post = [ 392,  237,  235, 311,  236, 394, 393, 316]\n",
    "    x_vals_post = [ 545,  457,  281, 280,  369, 280, 457, 633]\n",
    "    x_vals_post = (764 - np.array(x_vals_post)).tolist()\n",
    "    y_vals_post = (615 - np.array(y_vals_post)).tolist()\n",
    "    easting_scale = 0.02617801 # design I\n",
    "    northing_scale = 0.022764228   \n",
    "    post_rect_name = \"IMG_DesignIContourPlot_V000_20220505.png\"\n",
    "    \n",
    "    if filename[-2:] == \"16\":\n",
    "        test_duration = 155 # seconds\n",
    "    elif filename[-2:] == \"14\" or filename[-2:] == \"15\":\n",
    "        test_duration = 329 # seconds\n",
    "    else:\n",
    "        test_duration = 50 # seconds\n",
    "        \n",
    "elif id_str == \"RR1\":\n",
    "    model_scale_factor_dist = 29.5\n",
    "    model_name = 'wave_tracking_tf_lab_sm_v24.model'\n",
    "    \n",
    "    #             # G18   G24  G38 G40E  G26\n",
    "    x_vals_pre =  [ 693, 1040, 802, 118, 100] \n",
    "    y_vals_pre =  [ 369,  292, 234, 256, 330]\n",
    "    y_vals_post = [ 295,  222, 220, 369, 368]\n",
    "    x_vals_post = [ 510,  427, 263, 261, 427]\n",
    "    x_vals_post = (715 - np.array(x_vals_post)).tolist()\n",
    "    y_vals_post = (575 - np.array(y_vals_post)).tolist()\n",
    "    easting_scale = 0.027972028 # design H\n",
    "    northing_scale = 0.024347826\n",
    "    post_rect_name = \"IMG_DesignHContourPlot_V000_20220505.png\"\n",
    "    test_duration = 329 # seconds\n",
    "    \n",
    "    # verification RR1p5_pt1_ground_truth\n",
    "    #              # G24  G38 G40E  G26\n",
    "    #x_vals_pre =  [ 349, 869, 845, 317] \n",
    "    #y_vals_pre =  [ 646, 623,  84, 115]\n",
    "    #y_vals_post = [ 222, 220, 369, 368]\n",
    "    #x_vals_post = [ 427, 263, 261, 427]\n",
    "    \n",
    "else:\n",
    "    print(\"id_str chosen is not an option, please choose the correct id_str\")\n",
    "    quit()\n",
    "\n",
    "new_model = tf.keras.models.load_model(model_name)\n",
    "model_scale_factor_time = model_scale_factor_dist**0.5\n",
    "total_time = test_duration*model_scale_factor_time\n",
    "    \n",
    "####### STEP 1: Find 4 rectification points ######\n",
    "cv2.imwrite(filename + \".jpg\", frame_rec)\n",
    "pre_rect_name = filename + \".jpg\"\n",
    "pre_rect_image = cv2.imread(pre_rect_name)\n",
    "post_rect_image = cv2.imread(post_rect_name)\n",
    "graph_image = post_rect_image.copy()\n",
    "graph_image = cv2.cvtColor(graph_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Read source image.\n",
    "im_src = cv2.imread(pre_rect_name)\n",
    "\n",
    "# Group camera coordinates and group map coordinates \n",
    "pts_src = []\n",
    "pts_dst = []\n",
    "for i in range(0, len(x_vals_pre), 1):\n",
    "    pts_src.append([x_vals_pre[i], y_vals_pre[i]])\n",
    "    pts_dst.append([x_vals_post[i], y_vals_post[i]])\n",
    "\n",
    "pts_src = np.array(pts_src)\n",
    "pts_dst = np.array(pts_dst)\n",
    "    \n",
    "# Read destination image.\n",
    "im_dst = cv2.imread(post_rect_name)\n",
    "\n",
    "# Calculate Homography\n",
    "h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# Warp camera image to GPS based on homography\n",
    "im_out = cv2.warpPerspective(im_src, h, (im_dst.shape[1], im_dst.shape[0]))\n",
    "\n",
    "# plot points on images\n",
    "for i in range(0, len(x_vals_pre), 1):\n",
    "    cv2.circle(im_src, (int(x_vals_pre[i]), int(y_vals_pre[i])), radius=5, \n",
    "               color=[0, (1 - i/len(x_vals_pre))*255, (i/len(x_vals_pre))*255], thickness=-1)\n",
    "    cv2.circle(im_dst, (int(x_vals_post[i]), int(y_vals_post[i])), radius=3, \n",
    "               color=[0, (1 - i/len(x_vals_pre))*255, (i/len(x_vals_pre))*255], thickness=-1)\n",
    "\n",
    "# Display images\n",
    "cv2.namedWindow(\"Source Image\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Source Image\", 1280, 720)\n",
    "cv2.imshow(\"Source Image\", im_src)\n",
    "cv2.imshow(\"Destination Image\", im_dst)\n",
    "cv2.imshow(\"Warped Source Image\", im_out)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function does all the image preperation before classification and tracking. The basic process\n",
    "involves reducing noise before motion detection (blurring frames to be compared), finding the difference between\n",
    "frames (motion detection) and then blob detection to segment the most significant motion (blob detection).\n",
    "\n",
    "Outputs: keypoints (special 'pt' type)\n",
    "\"\"\"\n",
    "def motion_detection(frame, comparison_frame, blur_pixels, blob_params, motion_sensitivity, bbox_size):\n",
    "    # blur frame before taking diff image\n",
    "    blur = cv2.blur(frame, blur_pixels)\n",
    "    blur_comparison = cv2.blur(comparison_frame, blur_pixels)\n",
    "\n",
    "    # motion detection\n",
    "    frame_diff_blur = cv2.subtract(blur, blur_comparison)\n",
    "\n",
    "    # blob detection process\n",
    "    detector = cv2.SimpleBlobDetector_create(blob_params)\n",
    "    frame_diff_blur_gray = cv2.cvtColor(frame_diff_blur, cv2.COLOR_BGR2GRAY)\n",
    "    _, frame_diff_blur_BW = cv2.threshold(frame_diff_blur_gray, motion_sensitivity, 255, cv2.THRESH_BINARY)\n",
    "    frame_diff_blur_BW = cv2.bitwise_not(frame_diff_blur_BW)\n",
    "\n",
    "    blobs_remaining = 100 # arbitrary number larger than 1 to start the loop\n",
    "    first_pass_blob = True\n",
    "    while blobs_remaining > 0:\n",
    "        if first_pass_blob == True:\n",
    "            keypoints_i = detector.detect(frame_diff_blur_BW)\n",
    "            keypoints = list(keypoints_i)\n",
    "            first_pass_blob = False\n",
    "        else:\n",
    "            keypoints_i = detector.detect(frame_diff_blur_BW)\n",
    "            if len(keypoints_i) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                keypoints.extend(keypoints_i)\n",
    "        \n",
    "        # mask out each detected keypoint\n",
    "        for keypoint_i in keypoints_i:\n",
    "            x_start_rec = int(keypoint_i.pt[0] - (3 / 2 * bbox_size))\n",
    "            x_end_rec = int(keypoint_i.pt[0] + (3 / 2 * bbox_size))\n",
    "            y_start_rec = int(keypoint_i.pt[1] - (1 * bbox_size))\n",
    "            y_end_rec = int(keypoint_i.pt[1] + (1 * bbox_size))\n",
    "            start_point_rec = (x_start_rec, y_start_rec)\n",
    "            end_point_rec = (x_end_rec, y_end_rec)\n",
    "            cv2.rectangle(frame_diff_blur_BW, start_point_rec, end_point_rec, color=(255, 255, 255), thickness=-1)\n",
    "        \n",
    "        kernel = np.ones((int(bbox_size/5), int(bbox_size/5)), np.uint8)\n",
    "        frame_diff_blur_BW = cv2.morphologyEx(frame_diff_blur_BW, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        blobs_remaining = len(keypoints_i)\n",
    "        #print(\"blobs remaining = \" + str(blobs_remaining))\n",
    "        \n",
    "    for i in range(0, len(keypoints), 1):\n",
    "        cv2.circle(frame_diff_blur_BW, (int(keypoints[i].pt[0]), int(keypoints[i].pt[1])), \n",
    "                   radius=5, color=[150, 150, 150], thickness=-1)\n",
    "    \n",
    "    cv2.namedWindow(\"blobs\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"blobs\", 1280, 720)\n",
    "    cv2.imshow(\"blobs\", frame_diff_blur_BW)\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "\"\"\"\n",
    "This function takes snapshots (of size of the bounding boxes) of all the detected areas of motion. Then it classifies\n",
    "each of the snapshots as a breaking wave or not a breaking wave. The relevant data associated with each breaking wave is\n",
    "stored in the 'objects' list. \n",
    "\n",
    "Outputs: wave_detected (bool)\n",
    "\"\"\"\n",
    "def breaking_wave_classification(centre_frame, keypoints, bbox_size, classification_threshold, frame_count, \n",
    "                                 expiry_countdown, processing_area_bottom, processing_area_top, processing_area_left, \n",
    "                                 processing_area_right, debug_flag, frame_show):\n",
    "    global objects\n",
    "    global IMG_SIZE\n",
    "\n",
    "    objects = [] #initialize this list variable\n",
    "\n",
    "    IMG_SIZE_WID = int(IMG_SIZE) # can change this if needed\n",
    "    image_data = []\n",
    "    tf_images = []\n",
    "    for keyPoint in keypoints:\n",
    "        # crop an image for each blob (located within the bounding box).\n",
    "        x_start = int(keyPoint.pt[0] - (3 / 2 * bbox_size))\n",
    "        x_finish = int(keyPoint.pt[0] + (3 / 2 * bbox_size))\n",
    "        y_start = int(keyPoint.pt[1] - (1 * bbox_size))\n",
    "        y_finish = int(keyPoint.pt[1] + (1 * bbox_size))\n",
    "\n",
    "        if y_finish > processing_area_bottom*centre_frame.shape[0]:\n",
    "            continue # don't process this blob\n",
    "        if y_start < processing_area_top*centre_frame.shape[0]:\n",
    "            continue # don't process this blob\n",
    "        if x_start < processing_area_left*centre_frame.shape[1]:\n",
    "            continue # don't process this blob\n",
    "        if x_finish > processing_area_right*centre_frame.shape[1]:\n",
    "            continue # don't process this blob\n",
    "\n",
    "\n",
    "        # error handling for the boundary of the image\n",
    "        if x_start <= 0:\n",
    "            continue\n",
    "        elif x_finish >= centre_frame.shape[1]:\n",
    "            continue\n",
    "        elif y_start <= 0:\n",
    "            continue\n",
    "        elif y_finish >= centre_frame.shape[0]:\n",
    "            continue\n",
    "        else:  # crop the image\n",
    "            image_data.append([int(keyPoint.pt[0]), int(keyPoint.pt[1])])\n",
    "            colour_image = centre_frame[y_start: y_finish, x_start: x_finish]\n",
    "            resized_image = cv2.resize(colour_image, (IMG_SIZE_WID, IMG_SIZE))\n",
    "            tf_images.append(resized_image)\n",
    "        \n",
    "        if debug_flag == True:\n",
    "            cv2.circle(frame_show, (int(keyPoint.pt[0]), int(keyPoint.pt[1])), radius=5, color=[100, 100, 100], thickness=-1)\n",
    "        \n",
    "    if len(tf_images) < 1:\n",
    "        wave_detected = False\n",
    "    else:\n",
    "        wave_detected = False\n",
    "        image_data_counter = 0\n",
    "        imshow_tf_images = tf_images\n",
    "        tf_images = np.array(tf_images)\n",
    "        tf_images = tf.keras.utils.normalize(tf_images, axis=1)\n",
    "        tf_images = tf_images.reshape(-1, IMG_SIZE, IMG_SIZE_WID, 3)\n",
    "        predictions = new_model.predict(tf_images)\n",
    "        for prediction in predictions:\n",
    "            #print(prediction[0])\n",
    "            #cv2.imshow(\"thresh_image\", imshow_tf_images[image_data_counter])\n",
    "            #cv2.waitKey()\n",
    "            if prediction[0] > classification_threshold:\n",
    "                #print(prediction[0])\n",
    "                #cv2.imshow(\"thresh_image\", imshow_tf_images[image_data_counter])\n",
    "                #cv2.waitKey()\n",
    "\n",
    "                # add all relevant values to 'objects' list\n",
    "                x_centroid = image_data[image_data_counter][0]\n",
    "                y_centroid = image_data[image_data_counter][1]\n",
    "                # both need to be lists since more centroid coordinates will be appended when tracked\n",
    "                centroid_x = [x_centroid]\n",
    "                centroid_y = [y_centroid]\n",
    "                detection_timestamp = [frame_count]\n",
    "\n",
    "                blob_cloud_mask = tf_images[image_data_counter]\n",
    "                # blob_cloud_mask functionality not added yet\n",
    "\n",
    "                object_contents = [centroid_x, centroid_y, blob_cloud_mask, detection_timestamp, expiry_countdown, 0, False]\n",
    "                objects.append(object_contents)\n",
    "\n",
    "                # flag that a wave has been detected\n",
    "                wave_detected = True\n",
    "                \n",
    "                if debug_flag == True:\n",
    "                    cv2.circle(frame_show, (x_centroid, y_centroid), radius=5, color=[0, 255, 0], thickness=-1)\n",
    "            else:\n",
    "                pass\n",
    "                #print(prediction[0])\n",
    "                #cv2.imshow(\"thresh_image\", imshow_tf_images[image_data_counter])\n",
    "                #cv2.waitKey()\n",
    "            image_data_counter = image_data_counter + 1\n",
    "\n",
    "    return wave_detected, frame_show\n",
    "\n",
    "\"\"\"\n",
    "This function updates the status of a tracked object. Outputs a boolean, \n",
    "which is true if the previous timestamp was the same for the object. False otherwise.\n",
    "\n",
    "Outputs: bool\n",
    "\"\"\"\n",
    "def update_tracked_object(object, expiry_countdown, closest_tracked_object_index):\n",
    "\n",
    "    global tracked_objects\n",
    "\n",
    "    # if the previous timestamp is the same, take the average of the timestamp and \n",
    "    # set the new centroid to the average of the two centroids.\n",
    "    if tracked_objects[closest_tracked_object_index][3][-1] == object[3][0]:\n",
    "        # add centroids to tracked object\n",
    "        tracked_objects[closest_tracked_object_index][0][-1] = int((object[0][0] + \n",
    "                                                                    tracked_objects[closest_tracked_object_index][0][-1])/2)\n",
    "        tracked_objects[closest_tracked_object_index][1][-1] = int((object[1][0] + \n",
    "                                                                    tracked_objects[closest_tracked_object_index][1][-1])/2)\n",
    "        # THIS METHOD IS SLIGHTLY SKEWED TOWARDS THE POSITION OF LAST POINT WITH THE SAME TIMESTAMP.\n",
    "        # MOVING AVERAGE ONLY IS ACCURATE FOR 2 POINTS, HOWEVER STILL DEEMED ACCEPTABLE FOR MORE THAN\n",
    "        # 2 POINTS IF CLOSELY LOCATED\n",
    "\n",
    "        # update mask -> simply pick the bigger mask\n",
    "        # MASK ACTUALLY ISNT DOING ANYTHING - won't do anything until functionality is added later\n",
    "        if np.sum(object[2]) > np.sum(tracked_objects[closest_tracked_object_index][2]):\n",
    "            tracked_objects[closest_tracked_object_index][2] = object[2]\n",
    "        else:\n",
    "            # don't change the mask\n",
    "            pass\n",
    "\n",
    "        # reset expiry count to initial value\n",
    "        tracked_objects[closest_tracked_object_index][4] = expiry_countdown\n",
    "\n",
    "        return True\n",
    "    else:\n",
    "        # add centroids to tracked object\n",
    "        tracked_objects[closest_tracked_object_index][0].append(object[0][0])\n",
    "        tracked_objects[closest_tracked_object_index][1].append(object[1][0])\n",
    "        # update mask\n",
    "        tracked_objects[closest_tracked_object_index][2] = object[2]\n",
    "        # add timestamp to tracked object\n",
    "        tracked_objects[closest_tracked_object_index][3].append(object[3][0])\n",
    "        # reset expiry count to initial value\n",
    "        tracked_objects[closest_tracked_object_index][4] = expiry_countdown\n",
    "\n",
    "        return False\n",
    "\"\"\"\n",
    "This function updates the coordinates and timestamps of object tracked in the tracked_objects list.\n",
    "Metrics to determine if an object is identified in a new position are the following:\n",
    "-overlapping of blob mask\n",
    "-centroid distance\n",
    "-blob_mask area similarity\n",
    "-time difference between detections\n",
    "\n",
    "Outputs: graphing_mat (list), frame (opencv image)\n",
    "\"\"\"\n",
    "def track_blobs(frame, frame_show, objects, expiry_countdown, centroid_norm_param, blob_sim_norm_param, \n",
    "                dist_coef, time_coef, diff_coef, overlap_coef, graphing_mat, graph, bbox_size, LW_ratio, \n",
    "                post_rect_image, h):\n",
    "    global tracked_objects\n",
    "    global cost_threshold\n",
    "\n",
    "    closest_tracked_object_index = 0 # simply initializing variable to avoid warnings\n",
    "    # for each object detected, compare to all tracked objects to see if there is enough correlation to associate them.\n",
    "    for object in objects:\n",
    "        tracking_index = 0\n",
    "        object_has_been_tracked = False\n",
    "        # initialized as a relatively large variable, this value is updated according to the \n",
    "        # object association with the lowest cost.\n",
    "        cost_min = 100 \n",
    "        for tracked_object in tracked_objects:\n",
    "            # check blob mask overlapping\n",
    "            object_mask = object[2]\n",
    "            tracked_object_mask = tracked_object[2]\n",
    "\n",
    "            # add cost to the if statement, such that the cost is a combination of the Metrics below\n",
    "            centroid_dist = ((((((object[0][0] - tracked_object[0][-1])*LW_ratio) ** 2) +\n",
    "                               ((((object[1][0] - tracked_object[1][-1])*(1-LW_ratio)) ** 2))\n",
    "                               ) ** 0.5) / centroid_norm_param) * dist_coef\n",
    "            time_difference = ((object[3][0] - tracked_object[3][-1]) / expiry_countdown) * time_coef\n",
    "            blob_overlap_value = (np.sum(object_mask * tracked_object_mask)/np.sum(object_mask))*overlap_coef\n",
    "            #blob_area_difference = ((((int(np.sum(tracked_object_mask)) - \n",
    "            #                           int(np.sum(object_mask)))**2)**0.5)/blob_sim_norm_param)*diff_coef\n",
    "            # overlap acts like a 'free pass' if there is any overlap, since it will negate the build up of the cost\n",
    "            cost = centroid_dist + time_difference #+ blob_area_difference - blob_overlap_value\n",
    "\n",
    "            #debugging\n",
    "            #print(\"overlap: \" + str(blob_overlap_value))\n",
    "            #print(\"centroid_distance: \" + str(centroid_dist))\n",
    "            #print(\"area_difference: \" + str(blob_area_difference))\n",
    "            #print(\"time_difference: \" + str(time_difference))\n",
    "            #print(\"tracked object: \" + str(tracked_object[3][-1]) + \" object: \" + str(object[3][0]))\n",
    "            #print(\"cost: \", cost)\n",
    "            #print(\"\\n\")\n",
    "            #cv2.namedWindow('tracked object', cv2.WINDOW_NORMAL)\n",
    "            #cv2.resizeWindow('tracked object', 480, 270)\n",
    "            #cv2.imshow(\"tracked object\", tracked_object_mask)\n",
    "            #cv2.namedWindow('object', cv2.WINDOW_NORMAL)\n",
    "            #cv2.resizeWindow('object', 480, 270)\n",
    "            #cv2.imshow(\"object\", object_mask)\n",
    "            #cv2.waitKey()\n",
    "\n",
    "            # iterate through all tracked objects and keep the index of the object that is most likely associated\n",
    "            if cost < cost_threshold:\n",
    "                if cost < cost_min:\n",
    "                    cost_min = cost\n",
    "                    closest_tracked_object_index = tracking_index\n",
    "                    object_has_been_tracked = True\n",
    "\n",
    "            tracking_index = tracking_index + 1\n",
    "\n",
    "        # if object could be associated with an older tracked object, \n",
    "        # update the tracked object by adding the associated object data\n",
    "        if object_has_been_tracked == True:\n",
    "            same_object = update_tracked_object(object, expiry_countdown, closest_tracked_object_index)\n",
    "\n",
    "            # If the object is 'trackable' (has been tracked at least 'trackable_threshold' times), \n",
    "            # plot currently visible tracked objects\n",
    "            if tracked_objects[closest_tracked_object_index][6] == True:\n",
    "                # only plot if its a new object. Don't print objects that have the same 'closest_tracked_object_index'\n",
    "                if same_object == False:\n",
    "                    point1 = (int(tracked_objects[closest_tracked_object_index][0][-1] - (3 / 2 * bbox_size)), \n",
    "                              int(tracked_objects[closest_tracked_object_index][1][-1] - (1 * bbox_size)))\n",
    "                    point2 = (int(tracked_objects[closest_tracked_object_index][0][-1] + (3 / 2 * bbox_size)), \n",
    "                              int(tracked_objects[closest_tracked_object_index][1][-1] + (1 * bbox_size)))\n",
    "                    cv2.circle(frame_show, (tracked_objects[closest_tracked_object_index][0][-1], \n",
    "                                            tracked_objects[closest_tracked_object_index][1][-1]), \n",
    "                               radius=2, color=[100, 255, 255])\n",
    "                    cv2.rectangle(frame_show, point1, point2, (0, 150, 255), 3)\n",
    "                    cv2.putText(frame_show, str(tracked_objects[closest_tracked_object_index][5]), \n",
    "                                (tracked_objects[closest_tracked_object_index][0][-1], \n",
    "                                 tracked_objects[closest_tracked_object_index][1][-1]),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                    # update the graphing data, including the unique colour for that tracked object\n",
    "                    # NOTE: initial setting up of graphing_mat is done within tracked_object_dropout() function\n",
    "                    graphing_mat[tracked_objects[closest_tracked_object_index][5]].append(\n",
    "                        [(tracked_objects[closest_tracked_object_index][0][-1], \n",
    "                          tracked_objects[closest_tracked_object_index][1][-1])])\n",
    "                    graph_colour_1 = int(((tracked_objects[closest_tracked_object_index][5]) * 100) % 255)\n",
    "                    graph_colour_2 = int(((tracked_objects[closest_tracked_object_index][5]) * 15) % 255)\n",
    "                    graph_colour_3 = int((255 - ((tracked_objects[closest_tracked_object_index][5]) * 50)) % 255)\n",
    "                    # draw on the graph\n",
    "                    cv2.circle(graph, (tracked_objects[closest_tracked_object_index][0][-1], \n",
    "                                       tracked_objects[closest_tracked_object_index][1][-1]), 1, \n",
    "                               (graph_colour_1, graph_colour_2, graph_colour_3), 2)\n",
    "\n",
    "                    # also draw rectified graph\n",
    "                    graph_p1 = tracked_objects[closest_tracked_object_index][0][-1]\n",
    "                    graph_p2 = tracked_objects[closest_tracked_object_index][1][-1]\n",
    "                    print([graph_p1, graph_p2])\n",
    "                    output = cv2.perspectiveTransform(np.array([[[graph_p1, graph_p2]]], dtype=\"float32\"), h)\n",
    "                    print(output)\n",
    "                    cv2.circle(post_rect_image, (int(output[0][0][0]), int(output[0][0][1])), 1,\n",
    "                               (graph_colour_1, graph_colour_2, graph_colour_3), 2)\n",
    "\n",
    "        # if the object detected could not be linked to any previous objects, add it as a new object\n",
    "        else:\n",
    "            tracked_objects.append(object)\n",
    "\n",
    "    return graphing_mat, frame, frame_show\n",
    "\n",
    "\"\"\"\n",
    "Checks if any of the tracked objects have expired. Also update trackable status where\n",
    "if the object has been tracked at least 'trackable_threshold' times, then it can be given an ID\n",
    "\n",
    "Outputs: graphing_mat (list)\n",
    "\"\"\"\n",
    "def tracked_object_dropout(trackable_threshold, graphing_mat, graph, filename, post_rect_image, h):\n",
    "    global tracked_objects\n",
    "    global tracking_ID\n",
    "\n",
    "    surviving_tracked_objects = [] # used to hold on to tracekd objects that haven't expired\n",
    "\n",
    "    # first subtract 1 expiry countdown value from every tracked object\n",
    "    for tracked_object in tracked_objects:\n",
    "        # if object won't expire, subtract 1 from expiry countdown and keep object\n",
    "        if tracked_object[4] > 1:\n",
    "            tracked_object[4] = tracked_object[4] - 1\n",
    "            surviving_tracked_objects.append(tracked_object)\n",
    "\n",
    "            # update trackable status when acceptable:\n",
    "            if tracked_object[6] == False:\n",
    "                # if there have been more than the threshold of timestamps\n",
    "                if len(tracked_object[3]) > trackable_threshold:\n",
    "                    # set status as trackable\n",
    "                    tracked_object[6] = True\n",
    "                    # give a tracking ID\n",
    "                    tracked_object[5] = tracking_ID\n",
    "                    tracking_ID = tracking_ID + 1\n",
    "\n",
    "                    # add to graphing_mat\n",
    "                    for i in range(0, trackable_threshold, 1):\n",
    "                        graphing_mat.append([(tracked_object[0][i], tracked_object[1][i])])\n",
    "                        # update the graphing data, including the unique colour for that tracked object\n",
    "                        graph_colour_1 = int(((tracked_object[5]) * 100) % 255)\n",
    "                        graph_colour_2 = int(((tracked_object[5]) * 15) % 255)\n",
    "                        graph_colour_3 = int((255 - ((tracked_object[5]) * 50)) % 255)\n",
    "                        # draw on the graph\n",
    "                        cv2.circle(graph, (tracked_object[0][i], tracked_object[1][i]), 1,\n",
    "                                   (graph_colour_1, graph_colour_2, graph_colour_3), 2)\n",
    "\n",
    "                        # also draw rectified graph\n",
    "                        graph_p1 = tracked_object[0][i]\n",
    "                        graph_p2 = tracked_object[1][i]\n",
    "                        print([graph_p1, graph_p2])\n",
    "                        output = cv2.perspectiveTransform(np.array([[[graph_p1, graph_p2]]], dtype=\"float32\"), h)\n",
    "                        print(output)\n",
    "                        cv2.circle(post_rect_image, (int(output[0][0][0]), int(output[0][0][1])), 1,\n",
    "                                   (graph_colour_1, graph_colour_2, graph_colour_3), 2)\n",
    "\n",
    "        # else write object to the data file and don't add to surviving_tracked_objects list\n",
    "        else:\n",
    "            sat_x = []\n",
    "            sat_y = []\n",
    "            # also draw rectified graph\n",
    "            graph_p1 = tracked_object[0]\n",
    "            graph_p2 = tracked_object[1]\n",
    "            for gp in range(0, len(graph_p1), 1):\n",
    "                output_2d = cv2.perspectiveTransform(np.array([[[graph_p1[gp], graph_p2[gp]]]], dtype=\"float32\"), h)\n",
    "                sat_x.append(output_2d[0][0][0])\n",
    "                sat_y.append(output_2d[0][0][1])\n",
    "            print(np.array([tracked_object[0], tracked_object[1], tracked_object[3], sat_x, sat_y]))\n",
    "            # Data Format: [x_centroid coordinate, y_centroid coordinate, timestamps (frames), \n",
    "            #               sat_x_coordinate, sat_y_coordinate]\n",
    "            data_csv = np.array([tracked_object[0], tracked_object[1], tracked_object[3], sat_x, sat_y])\n",
    "            # 1 if tracked for more than 'trackable_threshold' frames, 0 if tracked for less\n",
    "            space_csv = np.array([int(tracked_object[6])])\n",
    "            # write 5 rows of data, x coordinates, y coordinates and frame and rectified coordinates\n",
    "            with open(results_dir + \"/tracked_objects\" + filename + \".csv\", \"ab\") as csv_file:\n",
    "                np.savetxt(csv_file, data_csv, delimiter=\",\", fmt='%f')\n",
    "                np.savetxt(csv_file, space_csv, delimiter=\",\", fmt='%f')\n",
    "\n",
    "    # re-create 'tracked_objects' from the surviving objects\n",
    "    tracked_objects = surviving_tracked_objects\n",
    "\n",
    "    return graphing_mat\n",
    "\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%% FRAME COMPARISON SETUP %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "# These frames are used to allow motion detection by taking a difference image between different frames in the while loop.\n",
    "# The difference image will be between the current frame in the video 'frame' and the last frame 'comparison_frame'. \n",
    "# By changing the frames between the current frame and comparison frame more or less motion can be detected.\n",
    "frame_list = []\n",
    "for i in range(0, frame_comparison_range, 1):\n",
    "    _, framei = cap.read()\n",
    "    frame_list.append(framei)\n",
    "\n",
    "comparison_frame = frame_list[(frame_comparison_range - 1)]\n",
    "centre_frame = frame_list[int(frame_comparison_range/2)]\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%% INITIALIZATIONS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "# general initialisations\n",
    "centroid_norm_param = 0\n",
    "blob_similarity_norm_param = 0\n",
    "tracking_ID = 0\n",
    "objects = []\n",
    "tracked_objects = []\n",
    "\n",
    "# initialize file for saving data in\n",
    "open(results_dir + \"/tracked_objects\" + filename + \".csv\", \"wb\")\n",
    "with open(results_dir + \"/tracked_objects\" + filename + \".csv\", \"a\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"homography matrix\"])\n",
    "with open(results_dir + \"/tracked_objects\" + filename + \".csv\", \"ab\") as csv_file:\n",
    "    np.savetxt(csv_file, h, delimiter=\",\")\n",
    "with open(results_dir + \"/tracked_objects\" + filename + \".csv\", \"a\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"data\"])\n",
    "\n",
    "# blob parameter setup\n",
    "blob_params = cv2.SimpleBlobDetector_Params()\n",
    "blob_params.filterByArea = False # True\n",
    "blob_params.minArea = blob_area_min # how many pixels is acceptable per blob\n",
    "blob_params.filterByCircularity = False # True\n",
    "blob_params.minCircularity = 0.01\n",
    "blob_params.filterByConvexity = False # True\n",
    "blob_params.minConvexity = 0.01\n",
    "blob_params.filterByInertia = False # True\n",
    "blob_params.minInertiaRatio = 0.01\n",
    "\n",
    "##### graphing setup ########\n",
    "# graphing variables\n",
    "graphing_mat = []\n",
    "graph_ID = -1 # start at -1, if image tracking to be graphed it is initialized at 0\n",
    "# set the graph background to be a frame of the video to give the user a reference point for the tracked waves\n",
    "graph = frame_list[0] \n",
    "\n",
    "# plot boundaries of the region of the image to be processed\n",
    "cv2.line(graph, (0, int(processing_area_bottom*graph.shape[0])), \n",
    "         (graph.shape[1], int(processing_area_bottom*graph.shape[0])), (0,0,255), thickness=3)\n",
    "cv2.line(graph, (0, int(processing_area_top*graph.shape[0])), \n",
    "         (graph.shape[1], int(processing_area_top*graph.shape[0])), (0,0,255), thickness=3)\n",
    "cv2.line(graph, (int(processing_area_left*graph.shape[1]), 0), \n",
    "         (int(processing_area_left*graph.shape[1]), graph.shape[0]), (0,0,255), thickness=3)\n",
    "cv2.line(graph, (int(processing_area_right*graph.shape[1]), 0), \n",
    "         (int(processing_area_right*graph.shape[1]), graph.shape[0]), (0,0,255), thickness=3)\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%% MAIN WHILE LOOP %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "# 588 frames in Snapper_Rocks_10_05_2017.mp4, therefore frame rate = 29.97 fps or 30fps\n",
    "run_frame_rate = 1000 # a little bit faster just because of the time delays associated with the rest of the code.\n",
    "frame_count = frame_comparison_range # this value is a counter so not 0 indexed\n",
    "first_pass = True\n",
    "frame_start_count = 0\n",
    "frame_end_count = 0\n",
    "frame_show = cap.read()\n",
    "cap.set(1, frame_start)\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if frame_end_count > frame_end:\n",
    "        break\n",
    "    \n",
    "    if frame_skip > 0:\n",
    "        if frame_end_count % frame_skip == 0:\n",
    "            frame_count = frame_count + 1 \n",
    "            frame_end_count = frame_end_count + 1\n",
    "            continue\n",
    "\n",
    "    if ret == True:\n",
    "        frame_show = frame.copy()\n",
    "        \n",
    "        # debugging for vidos that dont play at correct frame rate and have duplicate frames\n",
    "        frame_diff_initial = cv2.subtract(frame, frame_list[0])\n",
    "        if cv2.sumElems(cv2.sumElems(frame_diff_initial))[0] < 1500000:\n",
    "            frame_count = frame_count + 1 \n",
    "            frame_end_count = frame_end_count + 1\n",
    "            continue\n",
    "        else:\n",
    "            \"\"\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% STEP 1: MOTION DETECTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "            # track motion in the image\n",
    "            keypoints = motion_detection(frame, comparison_frame, blur_pixels, blob_params, motion_sensitivity, bbox_size)\n",
    "\n",
    "            \"\"\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% STEP 2: BREAKING WAVE CLASSIFICATION %%%%%%%%%%%%%%%%%%\"\"\"\n",
    "            # classify areas of motion as breaking waves or not breaking waves. Keep those classfied as breaking waves\n",
    "            # follow through with tracking if any waves have been detected\n",
    "            classify_check, frame_show = breaking_wave_classification(centre_frame, keypoints, bbox_size, \n",
    "                                                                      classification_threshold, frame_count, \n",
    "                                                                      expiry_countdown, processing_area_bottom, \n",
    "                                                                      processing_area_top, processing_area_left, \n",
    "                                                                      processing_area_right, debug_flag, frame_show)\n",
    "            if classify_check == True:\n",
    "\n",
    "                if first_pass == True:\n",
    "                    # set objects as first tracked objects\n",
    "                    tracked_objects.extend(objects)\n",
    "                    first_pass = False\n",
    "\n",
    "                    # set normalization parameters\n",
    "                    centroid_norm_param = int((frame.shape[0] ** 2 + frame.shape[1] ** 2) ** 0.5)\n",
    "                    blob_similarity_norm_param = int(frame.shape[0] * frame.shape[1])\n",
    "                    \n",
    "                else:\n",
    "                    # track the waves\n",
    "                    graphing_mat, frame, frame_show = track_blobs(frame, frame_show, objects, expiry_countdown, \n",
    "                                                                  centroid_norm_param, blob_similarity_norm_param, \n",
    "                                                                  dist_coef, time_coef, diff_coef, overlap_coef, \n",
    "                                                                  graphing_mat, graph, bbox_size, LW_ratio, \n",
    "                                                                  post_rect_image, h)\n",
    "                    # check for dropout in tracking process\n",
    "                    graphing_mat = tracked_object_dropout(trackable_threshold, graphing_mat, graph, filename, \n",
    "                                                          post_rect_image, h)\n",
    "\n",
    "            \"\"\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% STEP 4: PLOTTING %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "            cv2.namedWindow(\"graph\", cv2.WINDOW_NORMAL)\n",
    "            cv2.resizeWindow(\"graph\", 1280, 720)\n",
    "            cv2.imshow(\"graph\", graph)\n",
    "            cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
    "            cv2.resizeWindow(\"frame\", 1280, 720)\n",
    "            cv2.imshow(\"frame\", frame)\n",
    "            cv2.namedWindow(\"frame_vid\", cv2.WINDOW_NORMAL)\n",
    "            cv2.resizeWindow(\"frame_vid\", 1280, 720)\n",
    "            cv2.imshow(\"frame_vid\", frame_show)\n",
    "            cv2.imshow(\"rect_graph\", post_rect_image)\n",
    "            cv2.waitKey(int(1000/run_frame_rate)) # essentially just means run the video as fast as possible\n",
    "\n",
    "            # frame comparison, cycle through the list so only 'frame_comparison_range' frames are stored\n",
    "            frame_list.insert(0, frame)\n",
    "            frame_list.pop(frame_comparison_range)\n",
    "            comparison_frame = frame_list[(frame_comparison_range - 1)]\n",
    "            centre_frame = frame_list[int(frame_comparison_range / 2)]\n",
    "            \n",
    "        frame_count = frame_count + 1 \n",
    "        frame_end_count = frame_end_count + 1\n",
    "        print(frame_end_count)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Expire all wave tracks\n",
    "for i in range(0, expiry_countdown, 1):\n",
    "    graphing_mat = tracked_object_dropout(trackable_threshold, graphing_mat, graph, filename, post_rect_image, h)\n",
    "\n",
    "# initialize file for saving data in\n",
    "open(results_dir + \"/\" + \"tracking_settings_\" + filename + \".csv\", \"wb\")\n",
    "with open(results_dir + \"/\" + \"tracking_settings_\" + filename + \".csv\", \"a\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    writer.writerow([\"frame_rate_vid\", frame_rate, \"frame_count\", frame_end_count,\n",
    "                     \"wave_tracking_model\", model_name,\n",
    "                     \"IMG_SIZE\", IMG_SIZE, \"processing_area_bottom\", processing_area_bottom, \n",
    "                     \"processing_area_top\", processing_area_top, \"processing_area_left\", processing_area_left, \n",
    "                     \"processing_area_right\", processing_area_right, \n",
    "                     \"classification_threshold\", classification_threshold, \"frame_comparison_range\",\n",
    "                     frame_comparison_range, \"blob_area_min\", blob_area_min,\n",
    "                     \"motion_sensitivity\", motion_sensitivity, \"trackable_threshold\", trackable_threshold,\n",
    "                     \"expiry_countdown\", expiry_countdown, \"cost_threshold\", cost_threshold,\n",
    "                     \"dist_coef\", dist_coef, \"LW_ratio\", LW_ratio,\n",
    "                     \"time_coef\", time_coef, \"bbox_size\", bbox_size, \"blur_pixels\", blur_pixels])\n",
    "\n",
    "# save an image of the graph\n",
    "cv2.imwrite(results_dir + \"/\" + filename + \"graph.jpg\", graph)\n",
    "\n",
    "# save an image of the graph\n",
    "cv2.imwrite(results_dir + \"/\" + filename + \"birds_eye.jpg\", post_rect_image)\n",
    "\n",
    "print(str(\"Tracking finished\"))\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do Gaussian smoothing before rectification\n",
    "\n",
    "# open csv file\n",
    "# first load the csv file into python with rectified values\n",
    "csv_file_name = results_dir + \"/tracked_objects\" + filename + \".csv\"\n",
    "# get all the tracks before rectification\n",
    "all_u_i = []\n",
    "all_v_i = []\n",
    "all_time_i = []\n",
    "with open(csv_file_name) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    wave_tracked = []\n",
    "    all_u = []\n",
    "    all_v = []\n",
    "    all_time = []\n",
    "    for row in csv_reader:\n",
    "        if line_count < 7:\n",
    "            # not a data cell\n",
    "            pass\n",
    "        # if at the end of a wave track\n",
    "        elif (line_count - 7) % 6 == 5:\n",
    "            if '' in row:\n",
    "                blank = row.index('')\n",
    "                row = row[0:blank]\n",
    "            else:\n",
    "                row = row[0:]\n",
    "            row = np.array([float(i) for i in row]) # convert strings to floats\n",
    "            wave_tracked.append(row)\n",
    "            # if wave lasted long enough\n",
    "            if float(wave_tracked[3][0]) == 1:\n",
    "                # append full set of wave track data to list\n",
    "                all_u_i.append(all_u)\n",
    "                all_v_i.append(all_v)\n",
    "                all_time_i.append(all_time)\n",
    "            else:\n",
    "                # don't append since wasn't flagged as a tracked wave (didn't last long enough)\n",
    "                pass\n",
    "            wave_tracked = []\n",
    "            all_u = []\n",
    "            all_v = []\n",
    "            all_time = []\n",
    "        else:\n",
    "            # if u value\n",
    "            if (line_count - 7) % 6 == 0:\n",
    "                if '' in row:\n",
    "                    blank = row.index('')\n",
    "                    row = row[0:blank]\n",
    "                else:\n",
    "                    row = row[0:]\n",
    "                u_row = np.array([float(i) for i in row]) # convert strings to floats\n",
    "                wave_tracked.append(u_row)\n",
    "                all_u.append(u_row)\n",
    "            # if v value\n",
    "            elif (line_count - 7) % 6 == 1:\n",
    "                if '' in row:\n",
    "                    blank = row.index('')\n",
    "                    row = row[0:blank]\n",
    "                else:\n",
    "                    row = row[0:]\n",
    "                v_row = np.array([float(i) for i in row]) # convert strings to floats\n",
    "                wave_tracked.append(v_row)\n",
    "                all_v.append(v_row)\n",
    "            elif (line_count - 7) % 6 == 2:\n",
    "                if '' in row:\n",
    "                    blank = row.index('')\n",
    "                    row = row[0:blank]\n",
    "                else:\n",
    "                    row = row[0:]\n",
    "                time_row = np.array([float(i) for i in row]) # convert strings to floats\n",
    "                wave_tracked.append(time_row)\n",
    "                all_time.append(time_row)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        line_count = line_count + 1\n",
    "\n",
    "smooth_graph = cv2.imread(pre_rect_name)\n",
    "        \n",
    "smooth_u_i = []\n",
    "smooth_v_i = []\n",
    "smooth_x_i = []\n",
    "smooth_y_i = []\n",
    "for i in range(0, len(all_time_i), 1):\n",
    "    \n",
    "    # smooth u and v values before rectification\n",
    "    smooth_u_i.append(gaussian_filter(all_u_i[i], sigma=smoothing_val_small)) # 1 is very small to avoid track trunctation\n",
    "    smooth_v_i.append(gaussian_filter(all_v_i[i], sigma=smoothing_val))\n",
    "    \n",
    "    # rectify all track points\n",
    "    smooth_graph_colour_1 = int(((i) * 100) % 255)\n",
    "    smooth_graph_colour_2 = int(((i) * 15) % 255)\n",
    "    smooth_graph_colour_3 = int((255 - ((i) * 50)) % 255)\n",
    "    smooth_xs = []\n",
    "    smooth_ys = []\n",
    "    for j in range(0, len(all_time_i[i][0]), 1):\n",
    "        output_2d = cv2.perspectiveTransform(np.array([[[smooth_u_i[i][0][j], smooth_v_i[i][0][j]]]], dtype=\"float32\"), h)\n",
    "        smooth_xs.append(output_2d[0][0][0])\n",
    "        smooth_ys.append(output_2d[0][0][1])\n",
    "        \n",
    "        # draw on the graph\n",
    "        cv2.circle(smooth_graph, (int(smooth_u_i[i][0][j]), int(smooth_v_i[i][0][j])), 1, \n",
    "                   (smooth_graph_colour_1, smooth_graph_colour_2, smooth_graph_colour_3), 2)\n",
    "    \n",
    "    smooth_x_i.append(smooth_xs)\n",
    "    smooth_y_i.append(smooth_ys)\n",
    "    \n",
    "cv2.namedWindow(\"smooth_graph\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"smooth_graph\", 1280, 720)\n",
    "cv2.imshow('smooth_graph', smooth_graph)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# initialize file for saving data in\n",
    "open(results_dir + \"/tracked_objects_smooth_\" + filename + \".csv\", \"wb\")\n",
    "with open(results_dir + \"/tracked_objects_smooth_\" + filename + \".csv\", \"a\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"homography matrix\"])\n",
    "with open(results_dir + \"/tracked_objects_smooth_\" + filename + \".csv\", \"ab\") as csv_file:\n",
    "    np.savetxt(csv_file, h, delimiter=\",\")\n",
    "with open(results_dir + \"/tracked_objects_smooth_\" + filename + \".csv\", \"a\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"data\"])\n",
    "\n",
    "# save as csv\n",
    "for i in range(0, len(all_time_i), 1):\n",
    "    data_csv = np.array([smooth_u_i[i][0], smooth_v_i[i][0], all_time_i[i][0], smooth_x_i[i], smooth_y_i[i]])\n",
    "    # 1 if tracked for more than 'trackable_threshold' frames, 0 if tracked for less\n",
    "    space_csv = np.array([1])\n",
    "    # write 5 rows of data, x coordinates, y coordinates and frame and rectified coordinates\n",
    "    with open(results_dir + \"/tracked_objects_smooth_\" + filename + \".csv\", \"ab\") as csv_file:\n",
    "        np.savetxt(csv_file, data_csv, delimiter=\",\", fmt='%f')\n",
    "        np.savetxt(csv_file, space_csv, delimiter=\",\", fmt='%f')\n",
    "\n",
    "print(\"Now producing stats and figures\")\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "colours_list = ['#FF0000', '#FFAC00', '#FFFF00', '#B9FF00', '#00FF00']\n",
    "legend_list = ['< 4s' , '< 8s'  , '< 12s'  , '< 16s'  , '>= 16s' ]\n",
    "\n",
    "custom_lines = []\n",
    "for j in range(0, len(legend_list), 1):\n",
    "    custom_lines.append(Line2D([0], [0], color=colours_list[j], lw=4))\n",
    "\n",
    "def find_true_north_dir(rise, run):\n",
    "    \n",
    "    if rise == 0 and run > 0:\n",
    "        deg = 90\n",
    "    elif rise == 0 and run < 0:\n",
    "        deg = 270\n",
    "    elif rise > 0 and run == 0:\n",
    "        deg = 0\n",
    "    elif rise < 0 and run == 0:\n",
    "        deg = 180\n",
    "    elif run > 0:\n",
    "        deg = 90 - np.degrees(math.atan(rise/run))\n",
    "    elif run < 0:\n",
    "        deg = 180 + 90 - np.degrees(math.atan(rise/run))\n",
    "    else:\n",
    "        print(\"unexpected condition for direction\")\n",
    "        quit()\n",
    "    return deg\n",
    "    \n",
    "# first load the csv file into python with rectified values\n",
    "csv_file_name = results_dir + \"/tracked_objects_smooth_\" + filename + \".csv\"\n",
    "# these 4 lists are different ways to store data which are useful in different ways for statistics\n",
    "all_eastings_i = []\n",
    "all_northings_i = []\n",
    "all_times_i = []\n",
    "with open(csv_file_name) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    wave_tracked = []\n",
    "    all_easting = []\n",
    "    all_northing = []\n",
    "    all_time = []\n",
    "    for row in csv_reader:\n",
    "        if line_count < 7:\n",
    "            # not a data cell\n",
    "            pass\n",
    "        # if at the end of a wave track\n",
    "        elif (line_count - 7) % 6 == 5:\n",
    "            if '' in row:\n",
    "                blank = row.index('')\n",
    "                row = row[0:blank]\n",
    "            else:\n",
    "                row = row[0:]\n",
    "            row = np.array([float(i) for i in row]) # convert strings to floats\n",
    "            wave_tracked.append(row)\n",
    "            # if wave lasted long enough\n",
    "            if float(wave_tracked[3][0]) == 1:\n",
    "                # append full set of wave track data to list\n",
    "                all_eastings_i.append(all_easting)\n",
    "                all_northings_i.append(all_northing)\n",
    "                all_times_i.append(all_time)\n",
    "            else:\n",
    "                # don't append since wasn't flagged as a tracked wave (didn't last long enough)\n",
    "                pass\n",
    "            wave_tracked = []\n",
    "            all_easting = []\n",
    "            all_northing = []\n",
    "            all_time = []\n",
    "        else:\n",
    "            # if x value, convert to easting\n",
    "            if (line_count - 7) % 6 == 3:\n",
    "                if '' in row:\n",
    "                    blank = row.index('')\n",
    "                    row = row[0:blank]\n",
    "                else:\n",
    "                    row = row[0:]\n",
    "                easting_row = np.array([float(i)*easting_scale for i in row]) # convert strings to floats\n",
    "                wave_tracked.append(easting_row)\n",
    "                all_easting.append(easting_row)\n",
    "            # if y value, convert to northing\n",
    "            elif (line_count - 7) % 6 == 4:\n",
    "                if '' in row:\n",
    "                    blank = row.index('')\n",
    "                    row = row[0:blank]\n",
    "                else:\n",
    "                    row = row[0:]\n",
    "                northing_row = np.array([float(i)*-northing_scale for i in row]) # convert strings to floats\n",
    "                wave_tracked.append(northing_row)\n",
    "                all_northing.append(northing_row)               \n",
    "            elif (line_count - 7) % 6 == 2:\n",
    "                if '' in row:\n",
    "                    blank = row.index('')\n",
    "                    row = row[0:blank]\n",
    "                else:\n",
    "                    row = row[0:]\n",
    "                time_row = np.array([float(i) for i in row]) # convert strings to floats\n",
    "                wave_tracked.append(time_row)\n",
    "                all_time.append(time_row)\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        line_count = line_count + 1\n",
    "    \n",
    "all_eastings = []\n",
    "all_northings = []\n",
    "all_times = []\n",
    "# remove any tracks outside image\n",
    "for i in range(0, len(all_eastings_i), 1):\n",
    "    \n",
    "    # check duration of each track\n",
    "    if ((max(all_times_i[i][0]) - min(all_times_i[i][0])) / frame_rate)*model_scale_factor_time < min_ride_duration:\n",
    "        continue\n",
    "\n",
    "    # approximate ride length of waves - simply measure start to finish point\n",
    "    smooth_easting_i = np.array(all_eastings_i[i])*model_scale_factor_dist\n",
    "    smooth_northing_i = np.array(all_northings_i[i])*model_scale_factor_dist\n",
    "\n",
    "    start_point = [smooth_easting_i[0][0], smooth_northing_i[0][0]]\n",
    "    finish_point = [smooth_easting_i[0][-1], smooth_northing_i[0][-1]]\n",
    "    ride_length = distance.euclidean(start_point, finish_point)\n",
    "    \n",
    "    # check distance of each track\n",
    "    if ride_length < min_ride_length:\n",
    "        continue\n",
    "    else:\n",
    "        all_eastings.append(all_eastings_i[i])\n",
    "        all_northings.append(all_northings_i[i])\n",
    "        all_times.append(all_times_i[i])\n",
    "\n",
    "############# STATISTICS ###########################\n",
    "\n",
    "print(\"total time calculated as \" + str(total_time) + \" seconds\")\n",
    "\n",
    "# find all wave durations\n",
    "wave_durations = []\n",
    "for i in range(0, len(all_times), 1):\n",
    "    wave_durations.append( ((max(all_times[i][0]) - min(all_times[i][0]))/frame_rate)*model_scale_factor_time )\n",
    "\n",
    "# find average wave duration\n",
    "average_wave_duration = np.mean(wave_durations)\n",
    "max_wave_duration = np.max(wave_durations)\n",
    "\n",
    "print(\"The average ride duration was \" + str(round((average_wave_duration), 2)) + \"s.\")\n",
    "print(\"The maximum ride duration was \" + str(round((max_wave_duration), 2)) + \"s.\")\n",
    "print(\"The total time was \" + str(round(total_time/60, 2)) + \"min.\")\n",
    "print(\"The ride rate was \" + str(round(len(all_times)/(total_time/60), 2)) + \"rides/min.\")\n",
    "\n",
    "average_ride_speeds = []\n",
    "ride_lengths = []\n",
    "ride_track_angles = []\n",
    "for i in range(0, len(all_eastings), 1):\n",
    "\n",
    "    # approximate ride length of waves - simply measure start to finish point\n",
    "    smooth_easting_i = np.array(all_eastings[i])*model_scale_factor_dist\n",
    "    smooth_northing_i = np.array(all_northings[i])*model_scale_factor_dist\n",
    "    start_point = [smooth_easting_i[0][0], smooth_northing_i[0][0]]\n",
    "    finish_point = [smooth_easting_i[0][-1], smooth_northing_i[0][-1]]\n",
    "    ride_length = distance.euclidean(start_point, finish_point)\n",
    "    ride_lengths.append( ride_length )\n",
    "    \n",
    "    # average angle of waves\n",
    "    rise = finish_point[1] - start_point[1]\n",
    "    run = finish_point[0] - start_point[0]\n",
    "    ride_angle_deg = find_true_north_dir(rise, run)\n",
    "    ride_track_angles.append(ride_angle_deg)\n",
    "    \n",
    "    # average speed of waves\n",
    "    average_speed = ride_length/wave_durations[i]\n",
    "    average_ride_speeds.append(average_speed)\n",
    "    \n",
    "print(\"The average ride length was \" + str(round(np.mean(ride_lengths), 2)) + \"m.\")\n",
    "print(\"The maximum ride length was \" + str(round(np.max(ride_lengths), 2)) + \"m.\")\n",
    "print(\"The average ride speed was \" + str(round(np.mean(average_ride_speeds), 2)) + \"m/s.\")\n",
    "print(\"The maximum ride speed was \" + str(round(np.max(average_ride_speeds), 2)) + \"m/s.\")\n",
    "\n",
    "# save text file with all stats\n",
    "with open(results_dir + \"/surf_amenity_stats_\" + filename + \".txt\", 'w') as txt_file:\n",
    "    txt_file.write(\"The average ride duration was \" + str(round((average_wave_duration), 2)) + \"s.\\n\")\n",
    "    txt_file.write(\"The maximum ride duration was \" + str(round((max_wave_duration), 2)) + \"s.\\n\")\n",
    "    txt_file.write(\"The total time was \" + str(round(total_time/60, 2)) + \"min.\\n\")\n",
    "    txt_file.write(\"The total number of rides were \" + str(len(all_times)) + \".\\n\")\n",
    "    txt_file.write(\"The ride rate was \" + str(round(len(all_times)/(total_time/60), 2)) + \"rides/min.\\n\")\n",
    "    txt_file.write(\"The average ride length was \" + str(round(np.mean(ride_lengths), 2)) + \"m.\\n\")\n",
    "    txt_file.write(\"The maximum ride length was \" + str(round(np.max(ride_lengths), 2)) + \"m.\\n\")\n",
    "    txt_file.write(\"The average ride speed was \" + str(round(np.mean(average_ride_speeds), 2)) + \"m/s.\\n\")\n",
    "    txt_file.write(\"The maximum ride speed was \" + str(round(np.max(average_ride_speeds), 2)) + \"m/s.\\n\")\n",
    "\n",
    "# initialize file for saving data in\n",
    "open(results_dir + \"/tracked_objects_filt_\" + filename + \".csv\", \"wb\")\n",
    "\n",
    "for i in range(0, len(all_eastings), 1):\n",
    "    # save all values in csv file [east, north, time]\n",
    "    data_csv = np.array([all_eastings[i][0], all_northings[i][0], all_times[i][0]])\n",
    "    # 1 if tracked for more than 'trackable_threshold' frames, 0 if tracked for less\n",
    "    len_csv = np.array([ride_lengths[i]])\n",
    "    dir_csv = np.array([ride_track_angles[i]])\n",
    "    speed_csv = np.array([average_ride_speeds[i]])\n",
    "    space_csv = np.array([int(1)])\n",
    "    # write rows of data\n",
    "    with open(results_dir + \"/tracked_objects_filt_\" + filename + \".csv\", \"ab\") as csv_file:\n",
    "        np.savetxt(csv_file, data_csv, delimiter=\",\", fmt='%f')\n",
    "        np.savetxt(csv_file, len_csv, delimiter=\",\", fmt='%f')   \n",
    "        np.savetxt(csv_file, dir_csv, delimiter=\",\", fmt='%f')   \n",
    "        np.savetxt(csv_file, speed_csv, delimiter=\",\", fmt='%f')   \n",
    "        np.savetxt(csv_file, space_csv, delimiter=\",\", fmt='%f')\n",
    "\n",
    "# show wave trajectories:\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "ax.imshow(graph_image, extent=[0, graph_image.shape[1]*easting_scale*model_scale_factor_dist, \n",
    "                               graph_image.shape[0]*-northing_scale*model_scale_factor_dist, 0]) # left, right, bottom, top\n",
    "ax.set_xlabel('Eastings (m)')\n",
    "ax.set_ylabel('Northings (m)')\n",
    "ax.set_title('Wave Peel Tracks')\n",
    "colours = cm.rainbow(np.linspace(0, 1, len(all_eastings)))\n",
    "for i in range(0, len(all_eastings), 1):\n",
    "    smooth_easting = np.array(all_eastings[i])*model_scale_factor_dist\n",
    "    smooth_northing = np.array(all_northings[i])*model_scale_factor_dist\n",
    "    ax.plot(smooth_easting[0], smooth_northing[0], color=colours[i], lw=0.5)\n",
    "\n",
    "plt.show()\n",
    "# save the plot\n",
    "fig.savefig(results_dir + \"/wave_tracks_\" + filename + \".png\", bbox_inches='tight', dpi=1200)\n",
    "\n",
    "# show wave trajectories ordered by duration:\n",
    "fig=plt.figure()\n",
    "ax0=fig.add_subplot(111)\n",
    "ax0.imshow(graph_image, extent=[0, graph_image.shape[1]*easting_scale*model_scale_factor_dist, \n",
    "                                graph_image.shape[0]*-northing_scale*model_scale_factor_dist, 0]) # left, right, bottom, top\n",
    "ax0.set_xlabel('Eastings (m)')\n",
    "ax0.set_ylabel('Northings (m)')\n",
    "ax0.set_title('Wave Peel Track Durations')\n",
    "for i in range(0, len(all_eastings), 1):\n",
    "    smooth_easting = np.array(all_eastings[i])*model_scale_factor_dist\n",
    "    smooth_northing = np.array(all_northings[i])*model_scale_factor_dist\n",
    "    \n",
    "    if wave_durations[i] < 4:\n",
    "        colour = colours_list[0]\n",
    "    elif wave_durations[i] < 8:\n",
    "        colour = colours_list[1]\n",
    "    elif wave_durations[i] < 12:\n",
    "        colour = colours_list[2]\n",
    "    elif wave_durations[i] < 16:\n",
    "        colour = colours_list[3]\n",
    "    else:\n",
    "        colour = colours_list[4]\n",
    "    \n",
    "    ax0.plot(smooth_easting[0], smooth_northing[0], color=colour, lw=2, alpha = 0.7)\n",
    "\n",
    "ax0.legend(custom_lines, legend_list)\n",
    "plt.show()\n",
    "# save the plot\n",
    "fig.savefig(results_dir + \"/wave_tracks_dur_\" + filename + \".png\", bbox_inches='tight', dpi=1200)\n",
    "\n",
    "# heat map of initial breaking positions\n",
    "fig=plt.figure()\n",
    "ax2=fig.add_subplot(111)\n",
    "ax2.imshow(graph_image, extent=[0, graph_image.shape[1]*easting_scale*model_scale_factor_dist, \n",
    "                                graph_image.shape[0]*-northing_scale*model_scale_factor_dist, 0]) # left, right, bottom, top\n",
    "ax2.set_xlabel('Eastings (m)')\n",
    "ax2.set_ylabel('Northings (m)')\n",
    "ax2.set_title('Initial Wave Peel Points')\n",
    "for i in range(0, len(all_eastings), 1):\n",
    "    # plot the first points from each wave\n",
    "    ax2.scatter(all_eastings[i][0][0]*model_scale_factor_dist, \n",
    "                all_northings[i][0][0]*model_scale_factor_dist, color='g', alpha = 0.5, s=3)\n",
    "\n",
    "plt.show()\n",
    "# save the plot\n",
    "fig.savefig(results_dir + \"/wave_init_brkpnts_\" + filename + \".png\", bbox_inches='tight', dpi=1200)\n",
    "\n",
    "# heat map of all breaking positions\n",
    "fig=plt.figure()\n",
    "ax3=fig.add_subplot(111)\n",
    "ax3.imshow(graph_image, extent=[0, graph_image.shape[1]*easting_scale*model_scale_factor_dist, \n",
    "                                graph_image.shape[0]*-northing_scale*model_scale_factor_dist, 0]) # left, right, bottom, top\n",
    "ax3.set_xlabel('Eastings (m)')\n",
    "ax3.set_ylabel('Northings (m)')\n",
    "ax3.set_title('All Wave Peel Points')\n",
    "for i in range(0, len(all_eastings), 1):\n",
    "    # plot the first points from each wave\n",
    "    ax3.scatter(all_eastings[i][0]*model_scale_factor_dist, \n",
    "                all_northings[i][0]*model_scale_factor_dist, color='r', alpha = 0.4, s=2)\n",
    "\n",
    "plt.show()\n",
    "# save the plot\n",
    "fig.savefig(results_dir + \"/wave_all_brkpnts_\" + filename + \".png\", bbox_inches='tight', dpi=1200)\n",
    "\n",
    "# histogram of ride lengths\n",
    "fig=plt.figure()\n",
    "plt.hist(ride_lengths, density=False, bins=16)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Ride Length (m)');\n",
    "plt.show()\n",
    "fig.savefig(results_dir + \"/ride_length_hist_\" + filename + \".png\", bbox_inches='tight')\n",
    "\n",
    "# create a ride speed rose petal plot\n",
    "def get_petal_speed_data(wpt_speeds, wpt_angles, wpt_lengths):\n",
    "    \n",
    "    #             N NNE  NE ENE   E ESE  SE SSE   S SSW  SW WSW   W WNW  NW NNW\n",
    "    hist_bins = [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]\n",
    "    dir_count =  [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]\n",
    "    for j in range(0, len(wpt_angles), 1):\n",
    "        \n",
    "        direction = wpt_angles[j]\n",
    "\n",
    "        if direction >= 348.75:\n",
    "            hist_bins[0] = (hist_bins[0]*dir_count[0] + wpt_speeds[j])/(dir_count[0] + 1)\n",
    "            dir_count[0] = dir_count[0] + 1\n",
    "        elif direction < 11.25:\n",
    "            hist_bins[0] = (hist_bins[0]*dir_count[0] + wpt_speeds[j])/(dir_count[0] + 1)\n",
    "            dir_count[0] = dir_count[0] + 1\n",
    "        elif direction >= 11.25 and direction < 33.75:\n",
    "            hist_bins[1] = (hist_bins[1]*dir_count[1] + wpt_speeds[j])/(dir_count[1] + 1)\n",
    "            dir_count[1] = dir_count[1] + 1\n",
    "        elif direction >= 33.75 and direction < 56.25:\n",
    "            hist_bins[2] = (hist_bins[2]*dir_count[2] + wpt_speeds[j])/(dir_count[2] + 1)\n",
    "            dir_count[2] = dir_count[2] + 1\n",
    "        elif direction >= 56.25 and direction < 78.75:\n",
    "            hist_bins[3] = (hist_bins[3]*dir_count[3] + wpt_speeds[j])/(dir_count[3] + 1)\n",
    "            dir_count[3] = dir_count[3] + 1\n",
    "        elif direction >= 78.75 and direction < 101.25:\n",
    "            hist_bins[4] = (hist_bins[4]*dir_count[4] + wpt_speeds[j])/(dir_count[4] + 1)\n",
    "            dir_count[4] = dir_count[4] + 1\n",
    "        elif direction >= 101.25 and direction < 123.75:\n",
    "            hist_bins[5] = (hist_bins[5]*dir_count[5] + wpt_speeds[j])/(dir_count[5] + 1)\n",
    "            dir_count[5] = dir_count[5] + 1\n",
    "        elif direction >= 123.75 and direction < 146.25:\n",
    "            hist_bins[6] = (hist_bins[6]*dir_count[6] + wpt_speeds[j])/(dir_count[6] + 1)\n",
    "            dir_count[6] = dir_count[6] + 1\n",
    "        elif direction >= 146.25 and direction < 168.75:\n",
    "            hist_bins[7] = (hist_bins[7]*dir_count[7] + wpt_speeds[j])/(dir_count[7] + 1)\n",
    "            dir_count[7] = dir_count[7] + 1\n",
    "        elif direction >= 168.75 and direction < 191.25:\n",
    "            hist_bins[8] = (hist_bins[8]*dir_count[8] + wpt_speeds[j])/(dir_count[8] + 1)\n",
    "            dir_count[8] = dir_count[8] + 1\n",
    "        elif direction >= 191.25 and direction < 213.75:\n",
    "            hist_bins[9] = (hist_bins[9]*dir_count[9] + wpt_speeds[j])/(dir_count[9] + 1)\n",
    "            dir_count[9] = dir_count[9] + 1\n",
    "        elif direction >= 213.75 and direction < 236.25:\n",
    "            hist_bins[10] = (hist_bins[10]*dir_count[10] + wpt_speeds[j])/(dir_count[10] + 1)\n",
    "            dir_count[10] = dir_count[10] + 1\n",
    "        elif direction >= 236.25 and direction < 258.75:\n",
    "            hist_bins[11] = (hist_bins[11]*dir_count[11] + wpt_speeds[j])/(dir_count[11] + 1)\n",
    "            dir_count[11] = dir_count[11] + 1\n",
    "        elif direction >= 258.75 and direction < 281.25:\n",
    "            hist_bins[12] = (hist_bins[12]*dir_count[12] + wpt_speeds[j])/(dir_count[12] + 1)\n",
    "            dir_count[12] = dir_count[12] + 1\n",
    "        elif direction >= 281.25 and direction < 303.75:\n",
    "            hist_bins[13] = (hist_bins[13]*dir_count[13] + wpt_speeds[j])/(dir_count[13] + 1)\n",
    "            dir_count[13] = dir_count[13] + 1\n",
    "        elif direction >= 303.75 and direction < 326.25:\n",
    "            hist_bins[14] = (hist_bins[14]*dir_count[14] + wpt_speeds[j])/(dir_count[14] + 1)\n",
    "            dir_count[14] = dir_count[14] + 1\n",
    "        else:\n",
    "            hist_bins[15] = (hist_bins[15]*dir_count[15] + wpt_speeds[j])/(dir_count[15] + 1)\n",
    "            dir_count[15] = dir_count[15] + 1\n",
    "\n",
    "    # Compute pie slices\n",
    "    N = 16\n",
    "    theta = np.linspace(0.0, 2 * np.pi, N, endpoint=False)\n",
    "    width = 2 * np.pi / N\n",
    "\n",
    "    return theta, hist_bins, width, dir_count\n",
    "\n",
    "theta_wpt, speed_bins_wpt, width_wpt, direction_bins_wpt = get_petal_speed_data(average_ride_speeds, \n",
    "                                                                                ride_track_angles, ride_lengths)\n",
    "fig = plt.figure()\n",
    "ax6 = fig.add_subplot(111, projection='polar')\n",
    "bars = ax6.bar(theta_wpt, speed_bins_wpt, width=width_wpt, bottom=0.0, alpha=0.5, color = '#f77605')\n",
    "ax6.set_title(\"Avg. Ride Speeds For WPT Directions\")\n",
    "ax6.set_theta_zero_location('N')\n",
    "ax6.set_theta_direction(-1)\n",
    "ax6.set_ylim([0,15])\n",
    "plt.show()\n",
    "fig.savefig(results_dir + \"/dir_speed_polar_\" + filename + \".png\", bbox_inches='tight')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax7 = fig.add_subplot(111, projection='polar')\n",
    "bars = ax7.bar(theta_wpt, direction_bins_wpt, width=width_wpt, bottom=0.0, alpha=0.5, color = 'b')\n",
    "\n",
    "ax7.set_title(\"WPT Directions Polar Histogram\")\n",
    "ax7.set_theta_zero_location('N')\n",
    "ax7.set_theta_direction(-1)\n",
    "ax7.set_ylim([0,80])\n",
    "plt.show()\n",
    "fig.savefig(results_dir + \"/dir_hist_\" + filename + \".png\", bbox_inches='tight')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
