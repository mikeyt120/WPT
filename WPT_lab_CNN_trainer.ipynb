{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "import random\n",
    "\n",
    "model_version = 'lab_sm_v36'\n",
    "\n",
    "folder_location = \"\" # you can put all these folders below in another folder if you want\n",
    "wp_loc = \"breaking_waves_lab_all\"\n",
    "non_wp_loc = \"non_breaking_waves_lab_all\"\n",
    "wp_test_loc = \"breaking_waves_lab_all_test\"\n",
    "non_wp_test_loc = \"non_breaking_waves_lab_all_test\"\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%%% GET IMAGES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "# With the following settings, the model took about 30 minutes to train on my laptop\n",
    "data = []\n",
    "IMG_SIZE = 64\n",
    "IMG_SIZE_WID = IMG_SIZE\n",
    "brightness_change = 40\n",
    "epochs = 20 # this was actually 60 for model 35, however that takes a while to train!\n",
    "batch_size = 128 # this was actually 64 for model 35, however 64 doesn't always converge\n",
    "training_val_ratio = 0.9\n",
    "random.seed(1)\n",
    "\n",
    "image_names = listdir(folder_location + wp_loc)\n",
    "for i in range(0, len(image_names), 1):\n",
    "    image_i = cv2.imread(folder_location + wp_loc + \"/\" + image_names[i])\n",
    "    image_i_flipped = cv2.flip(image_i, 1)\n",
    "    \n",
    "    # get the image size to be normalized\n",
    "    resized_image = cv2.resize(image_i, (IMG_SIZE_WID, IMG_SIZE))\n",
    "    resized_image_flipped = cv2.resize(image_i_flipped, (IMG_SIZE_WID, IMG_SIZE))\n",
    "\n",
    "    # increase the brightness of image\n",
    "    resized_image_bi = resized_image.copy()\n",
    "    resized_image_bi = np.where((255 - resized_image_bi) < brightness_change, 255, resized_image_bi + brightness_change)\n",
    "    resized_image_bi_f = resized_image_flipped.copy()\n",
    "    resized_image_bi_f = np.where((255 - resized_image_bi_f) < brightness_change, 255, resized_image_bi_f + brightness_change)\n",
    "\n",
    "    # decrease the brightness of image\n",
    "    resized_image_bd = resized_image.copy()\n",
    "    resized_image_bd = np.where((resized_image_bd) < brightness_change, 0, resized_image_bd - brightness_change)\n",
    "    resized_image_bd_f = resized_image_flipped.copy()\n",
    "    resized_image_bd_f = np.where((resized_image_bd_f) < brightness_change, 0, resized_image_bd_f - brightness_change)\n",
    "\n",
    "    # make a grayscale 3 channel image\n",
    "    resized_image_gray = cv2.merge([cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY), \n",
    "                                    cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY), \n",
    "                                    cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)])\n",
    "    resized_image_gray_f = cv2.merge([cv2.cvtColor(resized_image_flipped, cv2.COLOR_BGR2GRAY), \n",
    "                                      cv2.cvtColor(resized_image_flipped, cv2.COLOR_BGR2GRAY), \n",
    "                                      cv2.cvtColor(resized_image_flipped, cv2.COLOR_BGR2GRAY)])\n",
    "    \n",
    "    #cv2.imshow(\"test_a\", resized_image_flipped)\n",
    "    #cv2.imshow(\"test_b\", resized_image_bi)\n",
    "    #cv2.imshow(\"test_c\", resized_image_bd)\n",
    "    #cv2.imshow(\"rig\", resized_image_gray)\n",
    "    #cv2.imshow(\"rigf\", resized_image_gray_f)\n",
    "    #cv2.waitKey()\n",
    "    \n",
    "    data.append([resized_image, 1]) # 1 represents a breaking wave\n",
    "    data.append([resized_image_flipped, 1])\n",
    "    data.append([resized_image_bi, 1])\n",
    "    data.append([resized_image_bd, 1])\n",
    "    data.append([resized_image_bi_f, 1])\n",
    "    data.append([resized_image_bd_f, 1])\n",
    "    data.append([resized_image_gray, 1])\n",
    "    data.append([resized_image_gray_f, 1])\n",
    "    \n",
    "    \n",
    "image_names = listdir(folder_location + non_wp_loc)\n",
    "for i in range(0, len(image_names), 1):\n",
    "    image_i = cv2.imread(folder_location + non_wp_loc + \"/\" + image_names[i])\n",
    "    image_i_flipped = cv2.flip(image_i, 1)\n",
    "    \n",
    "    # get the image size to be normalized\n",
    "    resized_image = cv2.resize(image_i, (IMG_SIZE_WID, IMG_SIZE))\n",
    "    resized_image_flipped = cv2.resize(image_i_flipped, (IMG_SIZE_WID, IMG_SIZE))\n",
    "\n",
    "    # increase the brightness of image\n",
    "    resized_image_bi = resized_image.copy()\n",
    "    resized_image_bi = np.where((255 - resized_image_bi) < brightness_change, 255, resized_image_bi + brightness_change)\n",
    "    resized_image_bi_f = resized_image_flipped.copy()\n",
    "    resized_image_bi_f = np.where((255 - resized_image_bi_f) < brightness_change, 255, resized_image_bi_f + brightness_change)\n",
    "\n",
    "    # decrease the brightness of image\n",
    "    resized_image_bd = resized_image.copy()\n",
    "    resized_image_bd = np.where((resized_image_bd) < brightness_change, 0, resized_image_bd - brightness_change)\n",
    "    resized_image_bd_f = resized_image_flipped.copy()\n",
    "    resized_image_bd_f = np.where((resized_image_bd_f) < brightness_change, 0, resized_image_bd_f - brightness_change)\n",
    "    \n",
    "    # make a grayscale 3 channel image\n",
    "    resized_image_gray = cv2.merge([cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY), \n",
    "                                    cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY), \n",
    "                                    cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)])\n",
    "    resized_image_gray_f = cv2.merge([cv2.cvtColor(resized_image_flipped, cv2.COLOR_BGR2GRAY), \n",
    "                                      cv2.cvtColor(resized_image_flipped, cv2.COLOR_BGR2GRAY), \n",
    "                                      cv2.cvtColor(resized_image_flipped, cv2.COLOR_BGR2GRAY)])\n",
    "    \n",
    "    #cv2.imshow(\"test_a\", resized_image)\n",
    "    #cv2.imshow(\"test_b\", resized_image_bi)\n",
    "    #cv2.imshow(\"test_c\", resized_image_bd)\n",
    "    #cv2.imshow(\"rig\", resized_image_gray)\n",
    "    #cv2.imshow(\"rigf\", resized_image_gray_f)\n",
    "    #cv2.waitKey()\n",
    "    \n",
    "    data.append([resized_image, 0]) # 0 represents a non-breaking wave\n",
    "    data.append([resized_image_flipped, 0])\n",
    "    data.append([resized_image_bi, 0])\n",
    "    data.append([resized_image_bd, 0])\n",
    "    data.append([resized_image_bi_f, 0])\n",
    "    data.append([resized_image_bd_f, 0])\n",
    "    data.append([resized_image_gray, 0])\n",
    "    data.append([resized_image_gray_f, 0]) \n",
    "\n",
    "# Now randomize rows of data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Now setup a training set and test set\n",
    "data_train = data[0:int(training_val_ratio*len(data))]\n",
    "data_test = data[int(training_val_ratio*len(data)):]\n",
    "\n",
    "# Now split x data from y data\n",
    "x_train = np.array(list(map(list, zip(*data_train)))[0])\n",
    "y_train = np.array(list(map(list, zip(*data_train)))[1])\n",
    "\n",
    "# needs to all be numpy arrays to work in tensorflow\n",
    "x_test = np.array(list(map(list, zip(*data_test)))[0])\n",
    "x_test_show = x_test\n",
    "y_test = np.array(list(map(list, zip(*data_test)))[1])\n",
    "\n",
    "# normalize input features (which are the pixel values)\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "# reshape for convolutional compatability\n",
    "x_train = x_train.reshape(-1, IMG_SIZE, IMG_SIZE_WID, 3)\n",
    "x_test = x_test.reshape(-1, IMG_SIZE, IMG_SIZE_WID, 3)\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%%% MACHINE LEARNING %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "# create the tensorflow model\n",
    "model = Sequential()\n",
    "\n",
    "# like VGGnet 16\n",
    "model.add(Conv2D(32, (3,3), input_shape = x_train.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"SAME\"))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"SAME\"))\n",
    "\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"SAME\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, validation_split=0.1, epochs=epochs)\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%%% EVALUATION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "\n",
    "# validation loss and validation accuracy should be close to training loss and accuracy (otherwise overfitting!)\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "model.save('wave_tracking_tf_' + model_version + '.model')\n",
    "\n",
    "test_data = []\n",
    "test_image_names = listdir(folder_location + wp_test_loc)\n",
    "for i in range(0, len(test_image_names), 1):\n",
    "    image_i = cv2.imread(folder_location + wp_test_loc + \"/\" + test_image_names[i])\n",
    "    resized_image = cv2.resize(image_i, (IMG_SIZE_WID, IMG_SIZE))\n",
    "\n",
    "    test_data.append([resized_image, 1])\n",
    "\n",
    "test_image_names_non = listdir(folder_location + non_wp_test_loc)\n",
    "for i in range(0, len(test_image_names_non), 1):\n",
    "    image_i = cv2.imread(folder_location + non_wp_test_loc + \"/\" + test_image_names_non[i])\n",
    "    resized_image = cv2.resize(image_i, (IMG_SIZE_WID, IMG_SIZE))\n",
    "\n",
    "    test_data.append([resized_image, 0])\n",
    "\n",
    "# needs to all be numpy arrays to work in tensorflow\n",
    "x_tests = np.array(list(map(list, zip(*test_data)))[0])\n",
    "x_test_shows = x_tests\n",
    "y_tests = np.array(list(map(list, zip(*test_data)))[1])\n",
    "\n",
    "# normalize input features (which are the pixel values)\n",
    "x_tests = tf.keras.utils.normalize(x_tests, axis=1)\n",
    "\n",
    "# reshape for convolutional compatability\n",
    "x_tests = x_tests.reshape(-1, IMG_SIZE, IMG_SIZE_WID, 3)\n",
    "\n",
    "predictions = model.predict([x_tests])\n",
    "\n",
    "cv2.namedWindow('test output', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('test output', 400,300) # just a nice visualisation resolution\n",
    "cost_scores = []\n",
    "print(\"showing misclassified images with error > 0.3\")\n",
    "j = 0\n",
    "for prediction in predictions:\n",
    "    test_image = cv2.resize(x_test_shows[j], (IMG_SIZE_WID, IMG_SIZE))\n",
    "    if prediction - y_tests[j] > 0.3: # only show the worst images\n",
    "        print(\"diff = \" + str(prediction - y_tests[j]))\n",
    "        cv2.imshow(\"test output\", test_image)\n",
    "        cv2.waitKey()\n",
    "\n",
    "    cost_scores.append((prediction - y_tests[j]) ** 2)\n",
    "    j = j + 1\n",
    "\n",
    "MSE_test = np.mean(cost_scores)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Original number of labelled images = \" + str(len(listdir(folder_location + wp_loc)) \n",
    "                                                    + len(listdir(folder_location + non_wp_loc))))\n",
    "print(\"Number of images after augmentation = \" + str(len(data)))   \n",
    "print(\"training loss = \" + str(train_loss) + \", training accuracy = \" + str(train_acc))\n",
    "print(\"test loss     = \" + str(val_loss) + \", test accuracy     = \" + str(val_acc))\n",
    "print(\"total MSE for test images = \" + str(MSE_test))\n",
    "\n",
    "# save text file with all results\n",
    "with open(model_version + \".txt\", 'w') as txt_file:\n",
    "    \n",
    "    txt_file.write(\"training loss               = \" + \"{:.5f}\".format(train_loss))\n",
    "    txt_file.write(\"\\ntest loss                 = \" + \"{:.5f}\".format(val_loss))\n",
    "    txt_file.write(\"\\ntraining accuracy         = \" + \"{:.5f}\".format(train_acc))\n",
    "    txt_file.write(\"\\ntest accuracy             = \" + \"{:.5f}\".format(val_acc))\n",
    "    txt_file.write(\"\\ntotal MSE for test images = \" + \"{:.5f}\".format(MSE_test))\n",
    "    txt_file.write(\"\\ntotal no. aug images      = \" + \"{:.5f}\".format(len(data)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is useful to re-run the results for a particular model without having to train a new one (also you can't train the same model twice since it is not deterministic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "import random\n",
    "\n",
    "model_version = 'lab_sm_v35'\n",
    "\n",
    "folder_location = \"\" # you can put all these folders below in another folder if you want\n",
    "wp_loc = \"breaking_waves_lab_all\"\n",
    "non_wp_loc = \"non_breaking_waves_lab_all\"\n",
    "wp_test_loc = \"breaking_waves_lab_all_test\"\n",
    "non_wp_test_loc = \"non_breaking_waves_lab_all_test\"\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%%% GET IMAGES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "data = []\n",
    "IMG_SIZE = 64\n",
    "IMG_SIZE_WID = IMG_SIZE # can change this if needed\n",
    "\n",
    "model = tf.keras.models.load_model('wave_tracking_tf_' + model_version + '.model')\n",
    "\n",
    "test_data = []\n",
    "test_image_names = listdir(folder_location + wp_test_loc)\n",
    "for i in range(0, len(test_image_names), 1):\n",
    "    image_i = cv2.imread(folder_location + wp_test_loc + \"/\" + test_image_names[i])\n",
    "    resized_image = cv2.resize(image_i, (IMG_SIZE_WID, IMG_SIZE))\n",
    "\n",
    "    test_data.append([resized_image, 1])\n",
    "\n",
    "test_image_names_non = listdir(folder_location + non_wp_test_loc)\n",
    "for i in range(0, len(test_image_names_non), 1):\n",
    "    image_i = cv2.imread(folder_location + non_wp_test_loc + \"/\" + test_image_names_non[i])\n",
    "    resized_image = cv2.resize(image_i, (IMG_SIZE_WID, IMG_SIZE))\n",
    "\n",
    "    test_data.append([resized_image, 0])\n",
    "\n",
    "# needs to all be numpy arrays to work in tensorflow\n",
    "x_tests = np.array(list(map(list, zip(*test_data)))[0])\n",
    "x_test_shows = x_tests\n",
    "y_tests = np.array(list(map(list, zip(*test_data)))[1])\n",
    "\n",
    "# normalize input features (which are the pixel values)\n",
    "x_tests = tf.keras.utils.normalize(x_tests, axis=1)\n",
    "\n",
    "# reshape for convolutional compatability\n",
    "x_tests = x_tests.reshape(-1, IMG_SIZE, IMG_SIZE_WID, 3)\n",
    "\n",
    "predictions = model.predict([x_tests])\n",
    "\n",
    "cv2.namedWindow('test output', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('test output', 400,300) # just a nice visualisation resolution\n",
    "cost_scores = []\n",
    "print(\"showing misclassified images with error > 0.3\")\n",
    "j = 0\n",
    "for prediction in predictions:\n",
    "    test_image = cv2.resize(x_test_shows[j], (IMG_SIZE_WID, IMG_SIZE))\n",
    "    if prediction - y_tests[j] > 0.3: # only show the worst images\n",
    "        print(\"diff = \" + str(prediction - y_tests[j]))\n",
    "        cv2.imshow(\"test output\", test_image)\n",
    "        cv2.waitKey()\n",
    "\n",
    "    cost_scores.append((prediction - y_tests[j]) ** 2)\n",
    "    j = j + 1\n",
    "\n",
    "MSE_test = np.mean(cost_scores)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"total MSE for test images = \" + str(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
